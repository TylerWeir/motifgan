{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcVhra_NwNDU"
   },
   "source": [
    "# Set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G6ZdrN-wfKlt"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that TensorFlow can see the GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-OZIju8fnh5"
   },
   "outputs": [],
   "source": [
    "# Build the model containing the generator followed by the discriminator. \n",
    "# This model was originally designed for Fashion MINST\n",
    "\n",
    "\n",
    "codings_size = 100\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(25 * 75 * 128, input_shape=[codings_size]),\n",
    "    keras.layers.Reshape([25, 75, 128]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                                 activation=\"selu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\",\n",
    "                                 activation=\"tanh\"),\n",
    "])\n",
    "\n",
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2),\n",
    "                        input_shape=[100, 300, 1]),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"SAME\",\n",
    "                        activation=keras.layers.LeakyReLU(0.2)),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KERAS MODELS\n",
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(16 * 32 * 128),\n",
    "        layers.Reshape((16, 32, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fF8nkpXQV0Nv",
    "outputId": "94f18c94-fb14-4c3b-fbe0-89ee2ad7516d"
   },
   "outputs": [],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(128, 256, 1)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sd2V5Utmykxv",
    "outputId": "83c645ca-c1ec-46e3-f0ed-d9f16705a6c0"
   },
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss='binary_crossentropy', optimizer=\"rmsprop\")\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Co9M3Z7wL5E"
   },
   "source": [
    "# Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xy3g9yoWwUwi",
    "outputId": "afb2a409-e64f-478d-bd27-8f7142d5c83f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFvef2PxwkHu"
   },
   "outputs": [],
   "source": [
    "# Used to unzip a data set loaded to the drive\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"/content/drive/MyDrive/MotifGAN Capstone/spec_solo_dist_noise_1.zip\") as z:\n",
    "  z.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq630Yg6xCKk"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "WDHaoTLTQ6Zv",
    "outputId": "45995a73-3fb6-4dcc-a173-2029b89765cc"
   },
   "outputs": [],
   "source": [
    "os.mkdir(\"spec\")\n",
    "os.rename(\"negative\", \"spec/negative\")\n",
    "os.rename(\"positive\", \"spec/positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVWxRAgTxN9X"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "pos_img_name = random.choice(os.listdir('./spec/positive'))\n",
    "neg_img_name = random.choice(os.listdir('./spec/negative'))\n",
    "\n",
    "print(pos_img_name)\n",
    "pos_img = mpimg.imread(f'./spec/positive/{pos_img_name}')\n",
    "plt.figure()\n",
    "plt.imshow(pos_img)\n",
    "print(neg_img_name)\n",
    "neg_img = mpimg.imread(f'./spec/negative/{neg_img_name}')\n",
    "plt.figure()\n",
    "plt.imshow(neg_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeWoIKzCxZM2"
   },
   "source": [
    "# Create the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QY0txAxoxiCR",
    "outputId": "e57e2310-a542-4bae-c890-4d07ee50d8e1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Load dataset from directory with keras\n",
    "\n",
    "# sometimes a directory called .ipynb_checkpoints is present, remove it if so\n",
    "if os.path.isdir('./spec/.ipynb_checkpoints'):\n",
    "  os.removedirs(\"./spec/.ipynb_checkpoints\")\n",
    "\n",
    "train_dir = './spec/'\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    color_mode=\"grayscale\",\n",
    "    label_mode=None,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    image_size=(128,256),\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "dataset = train_ds.map(lambda x: x / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Straight from the microsoft tutorial \n",
    "# shows the spectrograms with their labels\n",
    "plt.figure(figsize=(50, 50))\n",
    "for images in train_ds.take(1):\n",
    "    for i in range(len(images)):\n",
    "        ax = plt.subplot(3, 5, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(np.float64))\n",
    "        plt.title(f\"img {i}\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8Ouaru6z6a-"
   },
   "source": [
    "# Training\n",
    "https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFApsZvS1yYS"
   },
   "source": [
    "1. Select a number of real images from the training set.\n",
    "2. Generate a number of fake images. This is done by sampling random noise vectors and creating images from them using the generator\n",
    "3. Train the discriminator for one or more epochs using both fake and real images. This will update on the discrimators weights by labeling all the real images as 1 and the fake images as 0.\n",
    "4. Generate another number of fake images\n",
    "5. Train the full GAN model for one or more epochs using only fake images. This will update only the generator's weights by labeling all fake images as 1. \n",
    "\n",
    "**SOURCE**: Link above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD4nOTZ0biK1"
   },
   "outputs": [],
   "source": [
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        \n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_5DX3hbbpwv"
   },
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"output/generated_img_%03d_%d.png\" % (epoch, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "l1ghK7-CbsU_",
    "outputId": "63304994-ee67-4045-81ee-0bcd66bbbac5"
   },
   "outputs": [],
   "source": [
    "epochs = 1000   # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=128)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=1, latent_dim=128)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GAN-Attempt-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
